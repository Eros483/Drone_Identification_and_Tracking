# ğŸ›° Drone Identification and Tracking

Detects and tracks drones, UCAVs and other flying objects in the provided video and image files.

Created for WESEE, MoD.

---
## ğŸ“¦ Respository
Clone the functionality-ready project:
```
git clone https://github.com/Eros483/Drone_Identification_and_Tracking
cd Drone_Identification_and_Tracking
```
---
## âš™ï¸ Environment Setup
1. We recommend using Anaconda for environment control.
2. Create the environment using the provided yml, and activate it.
```
conda env create -f environment.yml
conda activate object
```
---
## ğŸš€ Running the Frontend
```
streamlit run app.py
```
## ğŸ› ï¸ Frontend Preview
![Preview of Features](preview.png)

## ğŸ’¡ Project Structure
```
Drone_Identification_and_Tracking
â”œâ”€â”€â”€custom_dataset_yolo
â”‚   â”œâ”€â”€â”€images
â”‚   â”‚   â”œâ”€â”€â”€train
â”‚   â”‚   â””â”€â”€â”€val
â”‚   â””â”€â”€â”€labels
â”‚       â”œâ”€â”€â”€train
â”‚       â””â”€â”€â”€val
â”œâ”€â”€â”€dataset
â”‚   â”œâ”€â”€â”€test
â”‚   â”‚   â”œâ”€â”€â”€images
â”‚   â”‚   â””â”€â”€â”€labels
â”‚   â”œâ”€â”€â”€train
â”‚   â”‚   â”œâ”€â”€â”€images
â”‚   â”‚   â””â”€â”€â”€labels
â”‚   â””â”€â”€â”€valid
â”‚       â”œâ”€â”€â”€images
â”‚       â””â”€â”€â”€labels
â”œâ”€â”€â”€demo_videos
â”œâ”€â”€â”€result_videos
â”œâ”€â”€â”€runs
â”œâ”€â”€â”€app.py
â”œâ”€â”€â”€main.ipynb
â”œâ”€â”€â”€drone.yaml
â”œâ”€â”€â”€requirements.txt
â””â”€â”€â”€scraper.ipynb
```
## ğŸ“š Guide for pipeline utilised
1. For setting up custom dataset:
    - Utilise `scraper.ipynb` to create custom dataset.
        - Uses selenium and bing image search to search and download image relevant to query.
    
    - Download labelImg.exe to manually create labels for each created image.

2. For pre-created dataset on drones:
    - Download dataset via your preferred method from: 
        https://universe.roboflow.com/models/object-detection

3. Use `main.ipynb` and modify paths as per your system path setup.
    - Provides code for sequential training on pre-created dataset, and then the custom dataset.
    - Provides method to save the created model and the pytorch checkpoints for the trained yoloV8 model.
4. Modify `app.py`to run with the updated paths and created model.
5. run the frontend using ```streamlit run app.py```
---
